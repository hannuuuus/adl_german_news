{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6fa5def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import scipy.sparse as sp\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987569d2f48b5653",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plan:\n",
    "- data analysis for each dataset - done in other files\n",
    "- merge them\n",
    "- take out 50 datapoints for validation later\n",
    "- apply algorithm to label all data\n",
    "\n",
    "- export so i can use it on DL algo\n",
    "\n",
    "\n",
    "https://www.kaggle.com/code/adityarahul/fakenewsdetection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af71e15a11f729",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "load all labelled data and merge it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d350f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files(folder_path):\n",
    "    all_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    dataframes = [pd.read_csv(file) for file in all_files]\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d73ac63f16f5d9fd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelled_folder = r\"C:\\github\\news\\news\\german-news\\preprocess data\\data_ready_for_analysis\\labelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4c2f854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data = merge_csv_files(labelled_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "dc42e3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_outlet</th>\n",
       "      <th>provenance</th>\n",
       "      <th>query_keywords</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>author_person</th>\n",
       "      <th>author_organization</th>\n",
       "      <th>news_keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>body</th>\n",
       "      <th>Fake News</th>\n",
       "      <th>Extreme bias</th>\n",
       "      <th>clickbait</th>\n",
       "      <th>credible</th>\n",
       "      <th>body_len</th>\n",
       "      <th>has_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bild</td>\n",
       "      <td>https://www.bild.de/politik/ausland/politik-au...</td>\n",
       "      <td>linke, migration, csu, cdu</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>Filipp Piatov und Ralf Schuler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sie verspottete Deutsche als Kartoffeln: Aktiv...</td>\n",
       "      <td>Schon wieder sorgt eine Personalentscheidung d...</td>\n",
       "      <td>Schon wieder sorgt eine Personalentscheidung d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3574.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bild</td>\n",
       "      <td>https://www.bild.de/politik/ausland/politik-au...</td>\n",
       "      <td>israel</td>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>P. Tiede, A. Link und H.-J. Vehlewald</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reporter als Terror-Helfer: Die perfide Propag...</td>\n",
       "      <td>Es ist der 7. Oktober 2023. Der Tag, der alles...</td>\n",
       "      <td>Es ist der 7. Oktober 2023. Der Tag, der alles...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5226.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bild</td>\n",
       "      <td>https://www.bild.de/politik/inland/politik-inl...</td>\n",
       "      <td>fdp, csu, spd, cdu, afd, annalena baerbock, ch...</td>\n",
       "      <td>2023-06-19</td>\n",
       "      <td>2023-06-19</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>Filipp Piatov</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CDU, CSU, die Gruenen, SPD, Wuest Hendrik, Mer...</td>\n",
       "      <td>Streit in der CDU: Umfrage-Schlacht zwischen M...</td>\n",
       "      <td>In der CDU liegen die Nerven blank! Es tobt ei...</td>\n",
       "      <td>In der CDU liegen die Nerven blank! Spaetesten...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bild</td>\n",
       "      <td>https://www.bild.de/politik/ausland/politik-au...</td>\n",
       "      <td>israel, spd, olaf scholz</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BILD</td>\n",
       "      <td>Gaza-Streifen, Gaza, Israel, Hamas, Nahost-Kon...</td>\n",
       "      <td>Shani Louk ermordet  Scholz: Zeigt die ganze B...</td>\n",
       "      <td>Shani Louk wurde barbarisch ermordet. Das best...</td>\n",
       "      <td>Es ist das pure Grauen. Am 7. Oktober verschle...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2655.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bild</td>\n",
       "      <td>https://www.bild.de/regional/leipzig/leipzig-n...</td>\n",
       "      <td>abschiebung, migration, cdu</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>KARL KEIM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tunesien, Georgien, Sachsen, asylrecht, Schust...</td>\n",
       "      <td>Sachsen: Nur jede dritte Abschiebung findet wi...</td>\n",
       "      <td>In Sachsen klappt nur jede dritte Abschiebung....</td>\n",
       "      <td>Leipzig  In Sachsen wurden bisher in diesem Ja...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2447.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>welt</td>\n",
       "      <td>https://www.welt.de/politik/ausland/article242...</td>\n",
       "      <td>krieg, christ, ss, sp, ukraine, ns, spo, nazi,...</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newsteam, Russland-Ukraine-Krieg (24.2.2022), ...</td>\n",
       "      <td>Ukraine-News ++ Ukraines Verteidigungsminister...</td>\n",
       "      <td>Laut dem ukrainischen Verteidigungsminister bi...</td>\n",
       "      <td>Laut dem ukrainischen Verteidigungsminister bi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21564.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>welt</td>\n",
       "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
       "      <td>sp, terror, ns, spd, schi, rechtsextremismus, ss</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newsteam, Wehrbeauftragte, Hoegl, Eva, Reichsb...</td>\n",
       "      <td>Wehrbeauftragte fordert haerteres Vorgehen geg...</td>\n",
       "      <td>Nach der Razzia gegen ein mutmassliches Terror...</td>\n",
       "      <td>Nach der Razzia gegen ein mutmassliches Terror...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>welt</td>\n",
       "      <td>https://www.welt.de/politik/ausland/article242...</td>\n",
       "      <td>krieg, sp, ukraine, ns, spd, rki, schi, ss, rn...</td>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newsteam, Leopard 2, Russland-Ukraine-Krieg (2...</td>\n",
       "      <td>Leopard 2: USA fuer Lieferung deutscher Kampfp...</td>\n",
       "      <td>Kanzler Scholz will moderne westliche Kampfpan...</td>\n",
       "      <td>Kanzler Scholz will moderne westliche Kampfpan...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2616.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>welt</td>\n",
       "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
       "      <td>terror, ss, ns</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Schindler-Frederik, Bundestag WELT, AfD, Razzi...</td>\n",
       "      <td>Reichsbuerger-Razzia: Ermittler finden 93 Waff...</td>\n",
       "      <td>Bei der bundesweiten Razzia gegen eine Reichsb...</td>\n",
       "      <td>Bei der bundesweiten Razzia gegen eine Reichsb...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>welt</td>\n",
       "      <td>https://www.welt.de/politik/ausland/article242...</td>\n",
       "      <td>krieg, christ, klima, cdu, sp, terror, ukraine...</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newsteam, Selenskyj, Wolodymyr, Putin, Wladimi...</td>\n",
       "      <td>Ukraine-News ++ Kiew darf sich laut Bundesregi...</td>\n",
       "      <td>Nach Ansicht der Bundesregierung darf Kiew bei...</td>\n",
       "      <td>Nach Ansicht der Bundesregierung darf Kiew bei...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24094.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    news_outlet                                         provenance  \\\n",
       "0          bild  https://www.bild.de/politik/ausland/politik-au...   \n",
       "1          bild  https://www.bild.de/politik/ausland/politik-au...   \n",
       "2          bild  https://www.bild.de/politik/inland/politik-inl...   \n",
       "3          bild  https://www.bild.de/politik/ausland/politik-au...   \n",
       "4          bild  https://www.bild.de/regional/leipzig/leipzig-n...   \n",
       "..          ...                                                ...   \n",
       "310        welt  https://www.welt.de/politik/ausland/article242...   \n",
       "311        welt  https://www.welt.de/politik/deutschland/articl...   \n",
       "312        welt  https://www.welt.de/politik/ausland/article242...   \n",
       "313        welt  https://www.welt.de/politik/deutschland/articl...   \n",
       "314        welt  https://www.welt.de/politik/ausland/article242...   \n",
       "\n",
       "                                        query_keywords creation_date  \\\n",
       "0                           linke, migration, csu, cdu    2022-06-15   \n",
       "1                                               israel    2023-11-10   \n",
       "2    fdp, csu, spd, cdu, afd, annalena baerbock, ch...    2023-06-19   \n",
       "3                             israel, spd, olaf scholz    2023-10-30   \n",
       "4                          abschiebung, migration, cdu    2023-11-09   \n",
       "..                                                 ...           ...   \n",
       "310  krieg, christ, ss, sp, ukraine, ns, spo, nazi,...    2022-12-12   \n",
       "311   sp, terror, ns, spd, schi, rechtsextremismus, ss    2022-12-13   \n",
       "312  krieg, sp, ukraine, ns, spd, rki, schi, ss, rn...    2022-12-10   \n",
       "313                                     terror, ss, ns    2022-12-13   \n",
       "314  krieg, christ, klima, cdu, sp, terror, ukraine...    2022-12-07   \n",
       "\n",
       "    last_modified  crawl_date                          author_person  \\\n",
       "0      2022-06-15  2024-10-20         Filipp Piatov und Ralf Schuler   \n",
       "1      2023-11-10  2024-10-20  P. Tiede, A. Link und H.-J. Vehlewald   \n",
       "2      2023-06-19  2024-10-20                          Filipp Piatov   \n",
       "3      2023-10-30  2024-10-20                                    NaN   \n",
       "4      2023-11-09  2024-10-20                              KARL KEIM   \n",
       "..            ...         ...                                    ...   \n",
       "310    2022-12-12  2024-10-20                                    NaN   \n",
       "311    2022-12-13  2024-10-20                                    NaN   \n",
       "312    2022-12-10  2024-10-20                                    NaN   \n",
       "313    2022-12-13  2024-10-20                                    NaN   \n",
       "314    2022-12-08  2024-10-20                                    NaN   \n",
       "\n",
       "    author_organization                                      news_keywords  \\\n",
       "0                   NaN                                                NaN   \n",
       "1                   NaN                                                NaN   \n",
       "2                   NaN  CDU, CSU, die Gruenen, SPD, Wuest Hendrik, Mer...   \n",
       "3                  BILD  Gaza-Streifen, Gaza, Israel, Hamas, Nahost-Kon...   \n",
       "4                   NaN  Tunesien, Georgien, Sachsen, asylrecht, Schust...   \n",
       "..                  ...                                                ...   \n",
       "310                 NaN  Newsteam, Russland-Ukraine-Krieg (24.2.2022), ...   \n",
       "311                 NaN  Newsteam, Wehrbeauftragte, Hoegl, Eva, Reichsb...   \n",
       "312                 NaN  Newsteam, Leopard 2, Russland-Ukraine-Krieg (2...   \n",
       "313                 NaN  Schindler-Frederik, Bundestag WELT, AfD, Razzi...   \n",
       "314                 NaN  Newsteam, Selenskyj, Wolodymyr, Putin, Wladimi...   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Sie verspottete Deutsche als Kartoffeln: Aktiv...   \n",
       "1    Reporter als Terror-Helfer: Die perfide Propag...   \n",
       "2    Streit in der CDU: Umfrage-Schlacht zwischen M...   \n",
       "3    Shani Louk ermordet  Scholz: Zeigt die ganze B...   \n",
       "4    Sachsen: Nur jede dritte Abschiebung findet wi...   \n",
       "..                                                 ...   \n",
       "310  Ukraine-News ++ Ukraines Verteidigungsminister...   \n",
       "311  Wehrbeauftragte fordert haerteres Vorgehen geg...   \n",
       "312  Leopard 2: USA fuer Lieferung deutscher Kampfp...   \n",
       "313  Reichsbuerger-Razzia: Ermittler finden 93 Waff...   \n",
       "314  Ukraine-News ++ Kiew darf sich laut Bundesregi...   \n",
       "\n",
       "                                           description  \\\n",
       "0    Schon wieder sorgt eine Personalentscheidung d...   \n",
       "1    Es ist der 7. Oktober 2023. Der Tag, der alles...   \n",
       "2    In der CDU liegen die Nerven blank! Es tobt ei...   \n",
       "3    Shani Louk wurde barbarisch ermordet. Das best...   \n",
       "4    In Sachsen klappt nur jede dritte Abschiebung....   \n",
       "..                                                 ...   \n",
       "310  Laut dem ukrainischen Verteidigungsminister bi...   \n",
       "311  Nach der Razzia gegen ein mutmassliches Terror...   \n",
       "312  Kanzler Scholz will moderne westliche Kampfpan...   \n",
       "313  Bei der bundesweiten Razzia gegen eine Reichsb...   \n",
       "314  Nach Ansicht der Bundesregierung darf Kiew bei...   \n",
       "\n",
       "                                                  body  Fake News  \\\n",
       "0    Schon wieder sorgt eine Personalentscheidung d...        1.0   \n",
       "1    Es ist der 7. Oktober 2023. Der Tag, der alles...        1.0   \n",
       "2    In der CDU liegen die Nerven blank! Spaetesten...        0.0   \n",
       "3    Es ist das pure Grauen. Am 7. Oktober verschle...        0.0   \n",
       "4    Leipzig  In Sachsen wurden bisher in diesem Ja...        0.0   \n",
       "..                                                 ...        ...   \n",
       "310  Laut dem ukrainischen Verteidigungsminister bi...        0.0   \n",
       "311  Nach der Razzia gegen ein mutmassliches Terror...        0.0   \n",
       "312  Kanzler Scholz will moderne westliche Kampfpan...        0.0   \n",
       "313  Bei der bundesweiten Razzia gegen eine Reichsb...        0.0   \n",
       "314  Nach Ansicht der Bundesregierung darf Kiew bei...        0.0   \n",
       "\n",
       "     Extreme bias  clickbait  credible  body_len  has_label         label  \n",
       "0             1.0        1.0       0.0    3574.0       True  [1, 1, 1, 0]  \n",
       "1             1.0        0.0       0.0    5226.0       True  [1, 1, 0, 0]  \n",
       "2             1.0        0.0       0.0    3071.0       True  [0, 1, 0, 0]  \n",
       "3             0.0        0.0       1.0    2655.0       True  [0, 0, 0, 1]  \n",
       "4             0.0        0.0       1.0    2447.0       True  [0, 0, 0, 1]  \n",
       "..            ...        ...       ...       ...        ...           ...  \n",
       "310           0.0        0.0       1.0   21564.0       True  [0, 0, 0, 1]  \n",
       "311           0.0        0.0       1.0     972.0       True  [0, 0, 0, 1]  \n",
       "312           0.0        0.0       1.0    2616.0       True  [0, 0, 0, 1]  \n",
       "313           0.0        0.0       1.0    1464.0       True  [0, 0, 0, 1]  \n",
       "314           0.0        0.0       1.0   24094.0       True  [0, 0, 0, 1]  \n",
       "\n",
       "[315 rows x 19 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d2e4b61e6e352e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "extract 50 labelled datapoints for later validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "69491056958abbb7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_data = labelled_data.sample(n=25, random_state=42)\n",
    "remaining_data = labelled_data.drop(validation_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "878a7686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fake News        2.0\n",
       "Extreme bias     7.0\n",
       "clickbait        9.0\n",
       "credible        19.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['Fake News', 'Extreme bias', 'clickbait', 'credible']\n",
    "validation_data[labels].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1103910e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fake News        56.0\n",
       "Extreme bias     75.0\n",
       "clickbait        83.0\n",
       "credible        211.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['Fake News', 'Extreme bias', 'clickbait', 'credible']\n",
    "remaining_data[labels].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867000c5895027e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "load all unlabelled data and merge it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e13c59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_folder = r\"C:\\github\\news\\news\\german-news\\preprocess data\\data_ready_for_analysis\\unlabelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c372d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_data = merge_csv_files(unlabelled_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f573ad496dfc6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "43f444f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = remaining_data[['title', 'description', 'body']].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "y = remaining_data[['Fake News', 'Extreme bias', 'clickbait', 'credible']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "97c0dc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fake News        46.0\n",
       "Extreme bias     63.0\n",
       "clickbait        64.0\n",
       "credible        166.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[labels].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "799479ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fake News       10.0\n",
       "Extreme bias    12.0\n",
       "clickbait       19.0\n",
       "credible        45.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[labels].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8312ce2986906993",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "77c0ebbeb64f4ed8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68698f3a",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "20aea67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "base_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "multi_label_model = MultiOutputClassifier(base_model)\n",
    "multi_label_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#predict\n",
    "y_pred = multi_label_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f646b7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Fake News       0.00      0.00      0.00        10\n",
      "Extreme bias       0.00      0.00      0.00        12\n",
      "   clickbait       1.00      0.11      0.19        19\n",
      "    credible       0.80      0.96      0.87        45\n",
      "\n",
      "   micro avg       0.79      0.52      0.63        86\n",
      "   macro avg       0.45      0.27      0.26        86\n",
      "weighted avg       0.64      0.52      0.50        86\n",
      " samples avg       0.77      0.70      0.72        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=y.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199921b8",
   "metadata": {},
   "source": [
    "works better but need to work on fake news and extreme bias label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b6fee01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def multilabel_smote(X, y, smote):\n",
    "#     \"\"\"\n",
    "#     Multilabel SMOTE: Resample each label column independently and recombine.\n",
    "#     \"\"\"\n",
    "#     X_resampled_list = []\n",
    "#     y_resampled_list = []\n",
    "    \n",
    "#     for label in y.columns:\n",
    "#         print(f\"Applying SMOTE for label: {label}\")\n",
    "#         X_resampled, y_resampled = smote.fit_resample(X, y[label])\n",
    "#         X_resampled_list.append(X_resampled)\n",
    "#         y_resampled_list.append(y_resampled)\n",
    "    \n",
    "#     # Rekombinieren der Daten\n",
    "#     #min_len = min(len(x) for x in X_resampled_list.shape[0])\n",
    "#     X_resampled = X_resampled_list[0]  # Alle Resamplings teilen dieselbe X-Datenstruktur\n",
    "#     y_resampled = np.column_stack(y_resampled_list)\n",
    "#     return X_resampled, pd.DataFrame(y_resampled, columns=y.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ff73ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = multilabel_smote(X_train_tfidf, y_train, smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "bbbc3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampler = RandomOverSampler(random_state=42)\n",
    "# X_resampled, y_resampled = X_train_tfidf, y_train.copy()\n",
    "\n",
    "# for label in labels:\n",
    "#     print(f\"Resampling for label: {label}\")\n",
    "#     X_resampled, y_resampled[label] = oversampler.fit_resample(X_resampled, y_resampled[label])\n",
    "\n",
    "# # Modelltraining\n",
    "# base_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "# multi_label_model = MultiOutputClassifier(base_model)\n",
    "# multi_label_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# # Vorhersagen\n",
    "# y_pred = multi_label_model.predict(X_test_tfidf)\n",
    "\n",
    "# # Evaluierung\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc8cbd0",
   "metadata": {},
   "source": [
    "I try random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "79f373ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum count for oversampling: 166.0\n"
     ]
    }
   ],
   "source": [
    "target_labels_os = ['Fake News', 'Extreme bias', 'clickbait']\n",
    "X_resampled, y_resampled = X_train_tfidf, y_train.copy()\n",
    "oversampler = RandomOverSampler(sampling_strategy=1.0, random_state=42)\n",
    "max_count = y_resampled.sum().max()\n",
    "print(f\"Maximum count for oversampling: {max_count}\") #is 166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b71f4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_resampled, y_resampled = oversampler.fit_resample(X_resampled, y_resampled)\n",
    "# print(\"Label counts after oversampling:\")\n",
    "# print(y_resampled.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f28ad666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling for label: Fake News\n",
      "Oversampling for label: Extreme bias\n",
      "Oversampling for label: clickbait\n",
      "Label counts after oversampling:\n",
      "Fake News        90.0\n",
      "Extreme bias    104.0\n",
      "clickbait       108.0\n",
      "credible        166.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target_labels_os = ['Fake News', 'Extreme bias', 'clickbait']\n",
    "max_count = y_resampled.sum().max()\n",
    "\n",
    "for label in target_labels_os:\n",
    "    print(f\"Oversampling for label: {label}\")\n",
    "    \n",
    "    # Filter für die aktuelle Klasse\n",
    "    y_single_label = y_resampled[label]\n",
    "    \n",
    "    # Übersampling der aktuellen Klasse\n",
    "    X_resampled, y_single_label_resampled = oversampler.fit_resample(X_resampled, y_single_label)\n",
    "    \n",
    "    # Aktualisieren des resampleten Labels\n",
    "    y_resampled[label] = y_single_label_resampled\n",
    "\n",
    "if not isinstance(y_resampled, pd.DataFrame):\n",
    "    y_resampled = pd.DataFrame(y_resampled, columns=y_train.columns)\n",
    "\n",
    "print(\"Label counts after oversampling:\")\n",
    "print(y_resampled.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "382334f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "base_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "multi_label_model = MultiOutputClassifier(base_model)\n",
    "multi_label_model.fit(X_train_tfidf, y_resampled)\n",
    "\n",
    "#predict\n",
    "y_pred = multi_label_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "5c599dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Fake News       0.08      0.10      0.09        10\n",
      "Extreme bias       0.21      0.25      0.23        12\n",
      "   clickbait       0.39      0.37      0.38        19\n",
      "    credible       0.80      0.96      0.87        45\n",
      "\n",
      "   micro avg       0.55      0.63      0.59        86\n",
      "   macro avg       0.37      0.42      0.39        86\n",
      "weighted avg       0.54      0.63      0.58        86\n",
      " samples avg       0.64      0.78      0.67        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=y.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9f24d",
   "metadata": {},
   "source": [
    "i try to get equal sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "09e86226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling for label: Fake News\n",
      "Oversampling for label: Extreme bias\n",
      "Oversampling for label: clickbait\n",
      "Oversampling for label: credible\n",
      "Label counts after oversampling:\n",
      "Fake News        90.0\n",
      "Extreme bias    104.0\n",
      "clickbait       108.0\n",
      "credible        125.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "oversampler = RandomOverSampler(sampling_strategy=1.0, random_state=42)\n",
    "\n",
    "# Initialize the resampled dataset\n",
    "X_resampled, y_resampled = X_train_tfidf.copy(), y_train.copy()\n",
    "\n",
    "# Loop through each label in y_train (assuming y_train is a DataFrame)\n",
    "target_labels_os = ['Fake News', 'Extreme bias', 'clickbait', \"credible\"]\n",
    "\n",
    "# Apply oversampling to each label\n",
    "for label in target_labels_os:\n",
    "    print(f\"Oversampling for label: {label}\")\n",
    "    \n",
    "    # Create a temporary DataFrame with the label\n",
    "    y_single_label = y_resampled[label]\n",
    "    \n",
    "    # Oversample the current label\n",
    "    X_resampled, y_single_label_resampled = oversampler.fit_resample(X_resampled, y_single_label)\n",
    "    \n",
    "    # Update the resampled y_resampled for the current label\n",
    "    y_resampled[label] = y_single_label_resampled\n",
    "\n",
    "# Ensure y_resampled is a DataFrame if it isn't already\n",
    "if not isinstance(y_resampled, pd.DataFrame):\n",
    "    y_resampled = pd.DataFrame(y_resampled, columns=y_train.columns)\n",
    "\n",
    "# Print the label counts after oversampling\n",
    "print(\"Label counts after oversampling:\")\n",
    "print(y_resampled.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "3cbc26cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "5034ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    if np.sum(y_pred[i]) == 0:  # If all labels are False (0)\n",
    "        # Set the first label to True (or choose another strategy)\n",
    "        y_pred[i, -1] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "62c6cc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 1., 1., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "4ba4dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "base_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "multi_label_model = MultiOutputClassifier(base_model)\n",
    "multi_label_model.fit(X_train_tfidf, y_resampled)\n",
    "\n",
    "#predict\n",
    "y_pred = multi_label_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "73b87aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Fake News       0.08      0.10      0.09        10\n",
      "Extreme bias       0.21      0.25      0.23        12\n",
      "   clickbait       0.39      0.37      0.38        19\n",
      "    credible       0.88      0.62      0.73        45\n",
      "\n",
      "   micro avg       0.51      0.45      0.48        86\n",
      "   macro avg       0.39      0.34      0.36        86\n",
      "weighted avg       0.58      0.45      0.51        86\n",
      " samples avg       0.51      0.56      0.52        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=y.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c8bef",
   "metadata": {},
   "source": [
    "keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c18ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "input_shape = X_train.shape[1]\n",
    "num_labels = y_train.shape[1]\n",
    "\n",
    "# model architecture\n",
    "model = Sequential([\n",
    "    Dense(512, input_shape=(input_shape,), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(num_labels, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# model summary\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train.toarray(), y_train.values, epochs=100, validation_split=0.4, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')  \n",
    "\n",
    "# To load the model later and resume training:\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('/kaggle/input/multiclass_seq/keras/default/1/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test.toarray(), y_test.values)\n",
    "print(f'Test Accuracy= {round(test_accuracy,2)*100}%\\nTest Loss= {round(test_loss,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80219dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7afa4ad",
   "metadata": {},
   "source": [
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f52cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: Fake News\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (604) does not match length of index (232)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[273], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m         X_resampled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([X_resampled, X_res])\n\u001b[1;32m---> 20\u001b[0m     \u001b[43my_resampled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y_resampled[label], y_res])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Modelltraining\u001b[39;00m\n\u001b[0;32m     23\u001b[0m base_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (604) does not match length of index (232)"
     ]
    }
   ],
   "source": [
    "oversampler = RandomOverSampler(random_state=42)\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = X_train_tfidf, y_train.copy()\n",
    "\n",
    "for label in labels:\n",
    "    print(f\"Processing label: {label}\")\n",
    "    \n",
    "    # Resampling für einzelne Klasse\n",
    "    pipeline = Pipeline([\n",
    "        ('oversample', oversampler),\n",
    "        ('undersample', undersampler)\n",
    "    ])\n",
    "    X_res, y_res = pipeline.fit_resample(X_resampled, y_resampled[label])\n",
    "    \n",
    "    # Update X und y\n",
    "    if sp.issparse(X_resampled):\n",
    "        X_resampled = sp.vstack([X_resampled, X_res])\n",
    "    else:\n",
    "        X_resampled = np.vstack([X_resampled, X_res])\n",
    "    y_resampled[label] = np.concatenate([y_resampled[label], y_res])\n",
    "\n",
    "# Modelltraining\n",
    "base_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "multi_label_model = MultiOutputClassifier(base_model)\n",
    "multi_label_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred = multi_label_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluierung\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddcf952",
   "metadata": {},
   "source": [
    "I try smote oversampling - currently not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from mlsmote import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_resampled, y_train_resampled = MLSMOTE(X_train_tfidf, y_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "# X_train_resampled, y_train_resampled = MLSMOTE(X_train_tfidf, y_train, 100)\n",
    "\n",
    "# # Modelltraining\n",
    "# base_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "# multi_label_model = MultiOutputClassifier(base_model)\n",
    "# multi_label_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # Vorhersagen\n",
    "# y_pred = multi_label_model.predict(X_test_tfidf)\n",
    "\n",
    "# # Evaluierung\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b8b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote = SMOTE(random_state=42)\n",
    "# model = RandomForestClassifier(class_weight='balanced', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bcbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     ('smote', smote),\n",
    "#     # ('model', model)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b59f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = pipeline.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
