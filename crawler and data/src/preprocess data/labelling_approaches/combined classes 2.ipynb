{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import hamming_loss, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report, hamming_loss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files(folder_path):\n",
    "    all_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    dataframes = [pd.read_csv(file) for file in all_files]\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_folder = r\"C:\\github\\news\\news\\german-news\\preprocess data\\data_ready_for_analysis\\labelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data = merge_csv_files(labelled_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = labelled_data.sample(n=30, random_state=42)\n",
    "remaining_data = labelled_data.drop(validation_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Fake News', 'Extreme bias', 'clickbait', 'credible']\n",
    "validation_data[labels].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Fake News', 'Extreme bias', 'clickbait', 'credible']\n",
    "remaining_data[labels].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_folder = r\"C:\\github\\news\\news\\german-news\\preprocess data\\data_ready_for_analysis\\unlabelled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_data = merge_csv_files(unlabelled_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"Fake News\": 1,\n",
    "    \"Extreme bias\": 2,\n",
    "    \"clickbait\": 3,\n",
    "    \"credible\": 0\n",
    "}\n",
    "\n",
    "def map_labels(row):\n",
    "    labels = [label_mapping[label] for label in label_mapping if row[label] == 1]\n",
    "    return \"-\".join(map(str, sorted(labels))) if labels else \"none\"\n",
    "\n",
    "remaining_data[\"label\"] = remaining_data.apply(map_labels, axis=1)\n",
    "remaining_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "remaining_data['label']= le.fit_transform(remaining_data['label']) \n",
    "remaining_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = remaining_data[['title', 'description', 'body']].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "y = remaining_data[['label']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "# Print unique labels and their counts\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label: {label}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique classes after encoding:\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique classes after encoding:\", np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "results = {}\n",
    "\n",
    "# Fit and evaluate GradientBoostingClassifier\n",
    "gb_model = MultiOutputClassifier(GradientBoostingClassifier(random_state=42))\n",
    "gb_model.fit(X_train_tfidf, y_train)\n",
    "gb_pred = gb_model.predict(X_test_tfidf)\n",
    "gb_acc = accuracy_score(y_test, gb_pred)\n",
    "results['MultiOutputClassifier'] = gb_acc\n",
    "print(f\"Accuracy with MultiOutputClassifier: {gb_acc}\")\n",
    "\n",
    "# Fit and evaluate XGBoost\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train_tfidf, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test_tfidf)\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "results['XGBoost'] = xgb_acc\n",
    "print(f\"Accuracy with XGBoost: {xgb_acc}\")\n",
    "\n",
    "# Fit and evaluate LightGBM\n",
    "lgbm_model = LGBMClassifier(random_state=42)\n",
    "lgbm_model.fit(X_train_tfidf, y_train)\n",
    "lgbm_pred = lgbm_model.predict(X_test_tfidf)\n",
    "lgbm_acc = accuracy_score(y_test, lgbm_pred)\n",
    "results['LightGBM'] = lgbm_acc\n",
    "print(f\"Accuracy with LightGBM: {lgbm_acc}\")\n",
    "\n",
    "# Fit and evaluate CatBoost\n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "catboost_model.fit(X_train_tfidf, y_train)\n",
    "catboost_pred = catboost_model.predict(X_test_tfidf)\n",
    "catboost_acc = accuracy_score(y_test, catboost_pred)\n",
    "results['CatBoost'] = catboost_acc\n",
    "print(f\"Accuracy with CatBoost: {catboost_acc}\")\n",
    "\n",
    "# Fit and evaluate BaggingClassifier with DecisionTreeClassifier as base estimator\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), random_state=42, n_estimators=100)\n",
    "bagging_model.fit(X_train_tfidf, y_train)\n",
    "bagging_pred = bagging_model.predict(X_test_tfidf)\n",
    "bagging_acc = accuracy_score(y_test, bagging_pred)\n",
    "results['BaggingClassifier_DecisionTree'] = bagging_acc\n",
    "print(f\"Accuracy with BaggingClassifier (DecisionTree): {bagging_acc}\")\n",
    "\n",
    "# Optional: Evaluate BaggingClassifier with other base estimators\n",
    "# Uncomment the following to try KNeighborsClassifier or LogisticRegression as base estimators.\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# bagging_knn = BaggingClassifier(base_estimator=KNeighborsClassifier(), random_state=42, n_estimators=100)\n",
    "# bagging_knn.fit(X_train_tfidf, y_train)\n",
    "# bagging_knn_pred = bagging_knn.predict(X_test_tfidf)\n",
    "# bagging_knn_acc = accuracy_score(y_test, bagging_knn_pred)\n",
    "# results['BaggingClassifier_KNeighbors'] = bagging_knn_acc\n",
    "# print(f\"Accuracy with BaggingClassifier (KNeighbors): {bagging_knn_acc}\")\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# bagging_lr = BaggingClassifier(base_estimator=LogisticRegression(), random_state=42, n_estimators=100)\n",
    "# bagging_lr.fit(X_train_tfidf, y_train)\n",
    "# bagging_lr_pred = bagging_lr.predict(X_test_tfidf)\n",
    "# bagging_lr_acc = accuracy_score(y_test, bagging_lr_pred)\n",
    "# results['BaggingClassifier_LogisticRegression'] = bagging_lr_acc\n",
    "# print(f\"Accuracy with BaggingClassifier (LogisticRegression): {bagging_lr_acc}\")\n",
    "\n",
    "# Display all results\n",
    "print(\"\\nSummary of Model Accuracies:\")\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f\"{model_name}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "results = {}\n",
    "\n",
    "# Fit and evaluate GradientBoostingClassifier\n",
    "# gb_model = GradientBoostingClassifier(random_state=42)\n",
    "# gb_model.fit(X_train_tfidf, y_train)\n",
    "# gb_pred = gb_model.predict(X_test_tfidf)\n",
    "# gb_acc = accuracy_score(y_test, gb_pred)\n",
    "# results['GradientBoostingClassifier'] = gb_acc\n",
    "# print(f\"Accuracy with GradientBoostingClassifier: {gb_acc}\")\n",
    "\n",
    "# # Fit and evaluate XGBoost\n",
    "# xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "# xgb_model.fit(X_train_tfidf, y_train)\n",
    "# xgb_pred = xgb_model.predict(X_test_tfidf)\n",
    "# xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "# results['XGBoost'] = xgb_acc\n",
    "# print(f\"Accuracy with XGBoost: {xgb_acc}\")\n",
    "\n",
    "# # Fit and evaluate LightGBM\n",
    "# lgbm_model = LGBMClassifier(random_state=42)\n",
    "# lgbm_model.fit(X_train_tfidf, y_train)\n",
    "# lgbm_pred = lgbm_model.predict(X_test_tfidf)\n",
    "# lgbm_acc = accuracy_score(y_test, lgbm_pred)\n",
    "# results['LightGBM'] = lgbm_acc\n",
    "# print(f\"Accuracy with LightGBM: {lgbm_acc}\")\n",
    "\n",
    "# # Fit and evaluate CatBoost\n",
    "# catboost_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "# catboost_model.fit(X_train_tfidf, y_train)\n",
    "# catboost_pred = catboost_model.predict(X_test_tfidf)\n",
    "# catboost_acc = accuracy_score(y_test, catboost_pred)\n",
    "# results['CatBoost'] = catboost_acc\n",
    "# print(f\"Accuracy with CatBoost: {catboost_acc}\")\n",
    "\n",
    "# Fit and evaluate BaggingClassifier with DecisionTreeClassifier as base estimator\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), random_state=42, n_estimators=100)\n",
    "bagging_model.fit(X_train_tfidf, y_train)\n",
    "bagging_pred = bagging_model.predict(X_test_tfidf)\n",
    "bagging_acc = accuracy_score(y_test, bagging_pred)\n",
    "results['BaggingClassifier_DecisionTree'] = bagging_acc\n",
    "print(f\"Accuracy with BaggingClassifier (DecisionTree): {bagging_acc}\")\n",
    "\n",
    "# Optional: Evaluate BaggingClassifier with other base estimators\n",
    "# Uncomment the following to try KNeighborsClassifier or LogisticRegression as base estimators.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging_knn = BaggingClassifier(estimator=KNeighborsClassifier(), random_state=42, n_estimators=100)\n",
    "bagging_knn.fit(X_train_tfidf, y_train)\n",
    "bagging_knn_pred = bagging_knn.predict(X_test_tfidf)\n",
    "bagging_knn_acc = accuracy_score(y_test, bagging_knn_pred)\n",
    "results['BaggingClassifier_KNeighbors'] = bagging_knn_acc\n",
    "print(f\"Accuracy with BaggingClassifier (KNeighbors): {bagging_knn_acc}\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "bagging_lr = BaggingClassifier(estimator=LogisticRegression(), random_state=42, n_estimators=100)\n",
    "bagging_lr.fit(X_train_tfidf, y_train)\n",
    "bagging_lr_pred = bagging_lr.predict(X_test_tfidf)\n",
    "bagging_lr_acc = accuracy_score(y_test, bagging_lr_pred)\n",
    "results['BaggingClassifier_LogisticRegression'] = bagging_lr_acc\n",
    "print(f\"Accuracy with BaggingClassifier (LogisticRegression): {bagging_lr_acc}\")\n",
    "\n",
    "# Display all results\n",
    "print(\"\\nSummary of Model Accuracies:\")\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f\"{model_name}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=42, verbose=0),\n",
    "    \"BaggingClassifier_DecisionTree\": BaggingClassifier(estimator=DecisionTreeClassifier(), random_state=42, n_estimators=100),\n",
    "    \"BaggingClassifier_KNeighbors\": BaggingClassifier(estimator=KNeighborsClassifier(), random_state=42, n_estimators=100),\n",
    "    \"BaggingClassifier_LogisticRegression\": BaggingClassifier(estimator=LogisticRegression(), random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "# Evaluate each model using cross-validation\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model, X_train_tfidf, y_train, cv=kf, scoring='accuracy')\n",
    "    results[model_name] = {\n",
    "        \"mean_accuracy\": np.mean(scores),\n",
    "        \"cv_scores\": scores\n",
    "    }\n",
    "    \n",
    "    # Generate cross-validated predictions (for metrics like classification report)\n",
    "    y_pred_cv = cross_val_predict(model, X_train_tfidf, y_train, cv=kf)\n",
    "    print(f\"Cross-Validated Accuracy for {model_name}: {np.mean(scores):.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_train, y_pred_cv))\n",
    "\n",
    "# Display summarized results\n",
    "print(\"\\nSummary of Model Accuracies:\")\n",
    "for model_name, result in results.items():\n",
    "    print(f\"{model_name}: Mean Accuracy: {result['mean_accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
